{"val_loss":0.14869643215622222,"_runtime":257.470402688,"test_total":1011,"val_correct":819,"train_loss":0.0746246704154394,"_step":31,"best_model_path":"Checkpoints/2-Messungen-noTu-Tu/trainsample_2723/run_7/best_model.pt","val_probs_labels":{"artifact_path":"wandb-client-artifact://64ypytjfpb2z2ttud89cegezh1lxoos4hvpmuswe8gqn4on6iux3rw88t8epp2dk8hygdehhilx2o5oi4n90je1x4ohnze1jrvl1uvjmb9835vshxgm0zbj3h34gk622/val_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://hf9xvf7weavdwqo73rj93zwmyxfunknvvd8quoty5pl149muhl9do0eup34gr21uua2hlvvmi0g6ialc40p6xjtb9bc0u1oiekbhibbra6negnonlsj09yjipqvactgy:latest/val_probs_labels.table.json","path":"media/table/val_probs_labels_30_611085c75ec62a783c33.table.json","ncols":2,"nrows":851,"_type":"table-file","sha256":"611085c75ec62a783c33e2376998318ac2c83d0dba9d232e2045930ba89750b8","size":22110},"_wandb":{"runtime":257},"_timestamp":1.7487996001359265e+09,"test_accuracy":92.87833827893175,"test_probs_labels":{"path":"media/table/test_probs_labels_31_ff553d6733f390027ef5.table.json","ncols":2,"nrows":1011,"_type":"table-file","sha256":"ff553d6733f390027ef58a2fd908efafaea4e2d5bb41991abec6d9e795551ee6","size":26214,"artifact_path":"wandb-client-artifact://t6mtrtf5112mr1g5gjvs8xz7qe4hiifqecoj4qg0lpit2xrm5jkyahcuymlahqikgvi5v3grzhqq24ss95yxnwt3w5yg0poi6s3qz2qca8minrofsn0zp8ue1vgn0onr/test_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://h49sdrtahiqurltne8cs19zkrjxknwm8phum3f9jfvmkyswm58xafpauuaxku3arjdar9ivk92r93iwi1b33px19nccs2x7b928nc71dls1x7miim9l53mgf3lzpahb7:latest/test_probs_labels.table.json"},"test_correct":939,"specificity":0.9548387096466181,"epoch":22,"sensitivity":0.9667282809433136,"val_total":851,"test_confusion_matrix_table":{"artifact_path":"wandb-client-artifact://h5u7zgjlzizfnbntm2ybm0dtzfyhvrn63rkv2rsdw4gv6gvbn6drkj8lyt6ijrhpmi9v9ate8g60k79tr1qtbmduch3jydw8wtibbrezj0aa9z02095pf68u3fpbqwen/test_confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://3nyruhnm6x2nw3v3g8bmfs4l8pqoau6b5cb4b6gv83l8rltjvmyel5xdpl45yauoo7nmbsbeu39rdblgpfxycbi5vgw8e3r7i0y8iy6tqacir3xvyyfzlg1egrx5fv8s:latest/test_confusion_matrix_table.table.json","path":"media/table/test_confusion_matrix_table_31_3b52225d776497f37ebd.table.json","ncols":3,"nrows":4,"_type":"table-file","sha256":"3b52225d776497f37ebd382eda5fc575df19d78502ce4d6423f6e848d56df945","size":180},"val_incorrect":32,"test_incorrect":72,"auc":0.9910202134637172,"test_specificity":0.9654320987415943,"train_samples_used":2723,"test_auc":0.9817911420771707,"checkpoint_path":"Checkpoints/2-Messungen-noTu-Tu/trainsample_2723/run_7/checkpoint_epoch_020.pt","test_sensitivity":0.904290429027982,"val_accuracy":96.23971797884842}