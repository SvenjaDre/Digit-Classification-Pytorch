2025-05-23 22:20:52,877 INFO    Thread-4 (_run_job):1287535 [wandb_setup.py:_flush():70] Current SDK version is 0.19.11
2025-05-23 22:20:52,877 INFO    Thread-4 (_run_job):1287535 [wandb_setup.py:_flush():70] Configure stats pid to 1287535
2025-05-23 22:20:52,877 INFO    Thread-4 (_run_job):1287535 [wandb_setup.py:_flush():70] Loading settings from /nfs/homes/sdreyer/.config/wandb/settings
2025-05-23 22:20:52,878 INFO    Thread-4 (_run_job):1287535 [wandb_setup.py:_flush():70] Loading settings from /nfs/homes/sdreyer/Digit-Classification-Pytorch/wandb/settings
2025-05-23 22:20:52,878 INFO    Thread-4 (_run_job):1287535 [wandb_setup.py:_flush():70] Loading settings from environment variables
2025-05-23 22:20:52,878 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:setup_run_log_directory():724] Logging user logs to /nfs/homes/sdreyer/Digit-Classification-Pytorch/wandb/run-20250523_222052-hlsqn8kf/logs/debug.log
2025-05-23 22:20:52,878 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to /nfs/homes/sdreyer/Digit-Classification-Pytorch/wandb/run-20250523_222052-hlsqn8kf/logs/debug-internal.log
2025-05-23 22:20:52,879 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():852] calling init triggers
2025-05-23 22:20:52,879 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():857] wandb.init called with sweep_config: {'batch_size': 16, 'dropout': 0.5, 'epochs': 1000, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'train_samples': 3404}
config: {'_wandb': {}}
2025-05-23 22:20:52,879 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():893] starting backend
2025-05-23 22:20:52,879 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():897] sending inform_init request
2025-05-23 22:20:52,886 INFO    Thread-4 (_run_job):1287535 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-23 22:20:52,887 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():907] backend started and connected
2025-05-23 22:20:52,888 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_config_callback():1436] config_cb None None {'batch_size': 16, 'dropout': 0.5, 'epochs': 1000, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'train_samples': 3404}
2025-05-23 22:20:52,889 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():1005] updated telemetry
2025-05-23 22:20:52,935 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():1029] communicating run to backend with 90.0 second timeout
2025-05-23 22:20:53,370 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():1104] starting run threads in backend
2025-05-23 22:20:53,565 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_console_start():2573] atexit reg
2025-05-23 22:20:53,566 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_redirect():2421] redirect: wrap_raw
2025-05-23 22:20:53,567 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_redirect():2490] Wrapping output streams.
2025-05-23 22:20:53,567 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_redirect():2513] Redirects installed.
2025-05-23 22:20:53,571 INFO    Thread-4 (_run_job):1287535 [wandb_init.py:init():1150] run started, returning control to user process
2025-05-23 22:28:31,746 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_finish():2321] finishing run svenja-dreyer-tu-dortmund/Hyperparametersuch-noTu-T/hlsqn8kf
2025-05-23 22:28:31,747 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_atexit_cleanup():2538] got exitcode: 0
2025-05-23 22:28:31,747 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_restore():2520] restore
2025-05-23 22:28:31,747 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_restore():2526] restore done
2025-05-23 22:28:35,061 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_footer_history_summary_info():4188] rendering history
2025-05-23 22:28:35,062 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_footer_history_summary_info():4220] rendering summary
2025-05-23 22:28:35,063 INFO    Thread-4 (_run_job):1287535 [wandb_run.py:_footer_sync_info():4149] logging synced files
