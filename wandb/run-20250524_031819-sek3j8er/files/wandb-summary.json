{"sensitivity":0.9999999999815157,"train_samples_used":3404,"train_loss":0.6652235167997854,"checkpoint_path":"Checkpoints/Hyperparametersuch-noTu-T/sweet-sweep-55/checkpoint_epoch_010.pt","_timestamp":1.7480496946254833e+09,"val_probs_labels":{"nrows":851,"_type":"table-file","sha256":"18cdb5ba1952e848d23b173ce0cf4a1f3aa1aa163b5c74961c981b7ac12e771e","size":21315,"artifact_path":"wandb-client-artifact://ccze1iunvl5p6obokl4oz9kch5utktfbea3wwe3p6fnsh63izfyd2yslax1bagjlfxb96qmafso31xczyksqz10a5tiokpj3kfe3c8s9xstojsnix234mzm3rpqekdwd/val_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://zzv51se7arqis2d9xn3j9iiitxzmdge4eqqw8ryer00iwgblfcvbbrtux5lmwxdiuurifgd6832luni1t9m6ics0itiuszstm26rydil7z83vht7japtguojjfej0go3:latest/val_probs_labels.table.json","path":"media/table/val_probs_labels_14_18cdb5ba1952e848d23b.table.json","ncols":2},"_wandb":{"runtime":195},"epoch":14,"auc":0.5,"val_correct":541,"val_incorrect":310,"specificity":0,"val_accuracy":63.572267920094006,"_step":14,"val_loss":0.6577011304242271,"val_total":851,"_runtime":195.440703344}