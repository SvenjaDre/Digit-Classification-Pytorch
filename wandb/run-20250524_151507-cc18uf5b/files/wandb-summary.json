{"val_loss":0.11565497730459486,"val_correct":830,"checkpoint_path":"Checkpoints/Hyperparametersuch-noTu-T/earnest-sweep-90/checkpoint_epoch_030.pt","_timestamp":1.7480929710613108e+09,"auc":0.9972094687257766,"train_samples_used":3404,"sensitivity":0.9833641404624147,"train_loss":0.00227380644085955,"val_probs_labels":{"_type":"table-file","sha256":"ea41ea6026fe243723a086950800530a6cdff31276e89e5d973f17ad88e76bfe","size":17202,"artifact_path":"wandb-client-artifact://1q7kkyshyq9y1mz35yqizqos6ybjoaitr0ibbtc39ujmn37ga0gy4bwfwppyl4ae1nhcmjfezgp56ht66g3h5oyaa7a29cfyo7yseekjvqqtm7j9k7pzvfmpb6651qur/val_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://4k3uf70hwltisxkeqbwz1jkehio57xmodu6b1wazidxvep9e4xkip3dzxg6kj0788z9iij60yfcz16z58y0p9fe68uo1qxei2v3w7sy4l9lxzf700slnywed5m1f56ll:latest/val_probs_labels.table.json","path":"media/table/val_probs_labels_35_ea41ea6026fe243723a0.table.json","ncols":2,"nrows":851},"_runtime":463.480125892,"val_total":851,"val_incorrect":21,"_step":35,"_wandb":{"runtime":463},"specificity":0.9612903225496358,"epoch":33,"val_accuracy":97.53231492361927}