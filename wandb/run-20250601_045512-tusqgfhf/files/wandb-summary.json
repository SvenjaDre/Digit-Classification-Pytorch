{"_step":63,"val_probs_labels":{"size":13491,"artifact_path":"wandb-client-artifact://5oc1hsylud18mcs192b0k9b8dvppwxagbtq3yqyu38mkmk4utw62zskvmx249lsj0a1obtq8zo3g2nn7fzu1k31ak229bg5ht892mcp4t44nh1ortwcrj3m7ay8zlsy5/val_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://jd34r9riay645x5h9zr5tcs5whzbh4kn5m6rt677ka0fs0mfcg45p90dnocmafilczfp2ssitzlyl2xodvxqkn4zoevq9iwo2tu87exxojucxqn5oofdh2ythylw9jv7:latest/val_probs_labels.table.json","path":"media/table/val_probs_labels_62_08c8952259d43d58319a.table.json","ncols":2,"nrows":532,"_type":"table-file","sha256":"08c8952259d43d58319a68b15ba066757eeb70bda04c72ac88f645e63d18fd7c"},"checkpoint_path":"Checkpoints/2-Messungen-Gli-Men/trainsample_1064/run_7/checkpoint_epoch_040.pt","epoch":44,"test_incorrect":90,"val_total":532,"train_samples_used":1064,"test_confusion_matrix_table":{"artifact_path":"wandb-client-artifact://w3dt6cpkpl40611iltariutl3em2p40c8ek3c370opb5ry7dol44v3iq2sgix9hkz287w7lsf4zd1k4l2dais14qxtisqkple24shs08n4wacnsav8me4zyfprn56hha/test_confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://vy7qebacxkpmmuoqyzkgw0e4xwvizi64zga2e5oeu7vlvwwm6jnqkuhx4menkbtw201h6d9mihb5ha93d462eaj2yodknq9an8yt8vv1v1igqf2krlj9484684dek5yh:latest/test_confusion_matrix_table.table.json","path":"media/table/test_confusion_matrix_table_63_f32fe3c3fec891193c41.table.json","ncols":3,"nrows":4,"_type":"table-file","sha256":"f32fe3c3fec891193c413678ca5d3ac706b312bc51cc5cf9b28299df4b9b8980","size":192},"_wandb":{"runtime":254},"auc":0.9430518443115466,"test_specificity":0.9166666666361111,"val_incorrect":59,"best_model_path":"Checkpoints/2-Messungen-Gli-Men/trainsample_1064/run_7/best_model.pt","sensitivity":0.8927203064792061,"test_probs_labels":{"size":14854,"artifact_path":"wandb-client-artifact://duu3snsu0a0d3wtj8y6k7y49nwsm98ht6cbal3wl26haf8ick484a2mr77erf6pr60q9hpk4olubi7kz6wfggpxqjb4wgtmuo5qgzx11j7dhsaxcg6qtzx7zec1w0flw/test_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://drw5ayw1d8o5d5vfaqknpywclx9jt93iqixexv3pqludy0112mwnmfenp3rzxg4taacymzeo04kck0oemm001vyyf9vuhy0q2zmnu1gbppyfdjauzimvsln4s4k7dxqw:latest/test_probs_labels.table.json","path":"media/table/test_probs_labels_63_b441e99fdeb14ce90ab1.table.json","ncols":2,"nrows":606,"_type":"table-file","sha256":"b441e99fdeb14ce90ab1991673b220637e2bf040f8f26b4b8f98760d72b5a8d3"},"test_accuracy":85.14851485148515,"test_total":606,"val_accuracy":88.90977443609023,"_runtime":254.530148589,"_timestamp":1.7487467672597396e+09,"test_correct":516,"test_auc":0.9263071895424837,"specificity":0.8856088560558816,"test_sensitivity":0.7875816993206672,"val_loss":0.3564094424247742,"train_loss":0.15933220502403048,"val_correct":473}