{"val_probs_labels":{"path":"media/table/val_probs_labels_26_bc9efca4b40d4537cead.table.json","ncols":2,"nrows":532,"_type":"table-file","sha256":"bc9efca4b40d4537cead786cde1bca08cd56f7e6100bb2458aa095d6a307bbe5","size":13340,"artifact_path":"wandb-client-artifact://v2eoypv5538ub5kqpcdvgbm4hqg4rh3jj0zw6lxg21ewc8hcz44na8k62c05c3s5xnlwb3c8ofis31pp50uut9ky0i79m2zp2ry91l8ccp927c6x3zbqw4sayrc0xvwg/val_probs_labels.table.json","_latest_artifact_path":"wandb-client-artifact://681lx235vhd0bme2bflhg2ppnhnq91xv81l2x0iwu98hbsizglou6w4aehuaryjh94sqij2jctq9vc00ptouptz08g3llbgokxtunioti65kr7yz052qu1b1xvaib235:latest/val_probs_labels.table.json"},"specificity":0,"sensitivity":0.9999999999616858,"_timestamp":1.7481070084922562e+09,"_step":26,"val_incorrect":271,"checkpoint_path":"Checkpoints/Hyperparametersuch-Gli-Men/cerulean-sweep-28/checkpoint_epoch_020.pt","_wandb":{"runtime":235},"_runtime":235.897679613,"val_correct":261,"val_loss":0.6950108023250804,"auc":0.5,"val_accuracy":49.06015037593985,"val_total":532,"epoch":25,"train_loss":0.6935054659843445,"train_samples_used":2128}