2025-05-31 02:44:12,739 INFO    Thread-16 (_run_job):155399 [wandb_setup.py:_flush():70] Current SDK version is 0.19.11
2025-05-31 02:44:12,739 INFO    Thread-16 (_run_job):155399 [wandb_setup.py:_flush():70] Configure stats pid to 155399
2025-05-31 02:44:12,739 INFO    Thread-16 (_run_job):155399 [wandb_setup.py:_flush():70] Loading settings from /nfs/homes/sdreyer/.config/wandb/settings
2025-05-31 02:44:12,740 INFO    Thread-16 (_run_job):155399 [wandb_setup.py:_flush():70] Loading settings from /nfs/homes/sdreyer/Digit-Classification-Pytorch/wandb/settings
2025-05-31 02:44:12,740 INFO    Thread-16 (_run_job):155399 [wandb_setup.py:_flush():70] Loading settings from environment variables
2025-05-31 02:44:12,740 INFO    Thread-16 (_run_job):155399 [wandb_init.py:setup_run_log_directory():724] Logging user logs to /nfs/homes/sdreyer/Digit-Classification-Pytorch/wandb/run-20250531_024412-x1xw1hgv/logs/debug.log
2025-05-31 02:44:12,740 INFO    Thread-16 (_run_job):155399 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to /nfs/homes/sdreyer/Digit-Classification-Pytorch/wandb/run-20250531_024412-x1xw1hgv/logs/debug-internal.log
2025-05-31 02:44:12,741 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():852] calling init triggers
2025-05-31 02:44:12,741 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():857] wandb.init called with sweep_config: {'batch_size': 128, 'dropout': 0.55, 'epochs': 1000, 'learning_rate': 0.005, 'optimizer': 'Adam', 'train_samples': 2042}
config: {'_wandb': {}}
2025-05-31 02:44:12,741 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():893] starting backend
2025-05-31 02:44:12,742 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():897] sending inform_init request
2025-05-31 02:44:12,743 INFO    Thread-16 (_run_job):155399 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-31 02:44:12,743 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():907] backend started and connected
2025-05-31 02:44:12,744 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_config_callback():1436] config_cb None None {'batch_size': 128, 'dropout': 0.55, 'epochs': 1000, 'learning_rate': 0.005, 'optimizer': 'Adam', 'train_samples': 2042}
2025-05-31 02:44:12,745 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():1005] updated telemetry
2025-05-31 02:44:12,755 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():1029] communicating run to backend with 90.0 second timeout
2025-05-31 02:44:13,453 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():1104] starting run threads in backend
2025-05-31 02:44:13,616 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_console_start():2573] atexit reg
2025-05-31 02:44:13,616 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_redirect():2421] redirect: wrap_raw
2025-05-31 02:44:13,616 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_redirect():2490] Wrapping output streams.
2025-05-31 02:44:13,617 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_redirect():2513] Redirects installed.
2025-05-31 02:44:13,617 INFO    Thread-16 (_run_job):155399 [wandb_init.py:init():1150] run started, returning control to user process
2025-05-31 02:50:04,700 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_finish():2321] finishing run svenja-dreyer-tu-dortmund/Messungen-noTu-Tu/x1xw1hgv
2025-05-31 02:50:04,700 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_atexit_cleanup():2538] got exitcode: 0
2025-05-31 02:50:04,701 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_restore():2520] restore
2025-05-31 02:50:04,701 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_restore():2526] restore done
2025-05-31 02:50:08,092 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_footer_history_summary_info():4188] rendering history
2025-05-31 02:50:08,093 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_footer_history_summary_info():4220] rendering summary
2025-05-31 02:50:08,094 INFO    Thread-16 (_run_job):155399 [wandb_run.py:_footer_sync_info():4149] logging synced files
