\chapter{Methodik}\label{sec:methodik}
Um die Leistung des Modells bei unterschiedlichen Datensatzgrößen zu untersuchen, wird in dieser Arbeit ein Convolutional Neural Network (CNN) eingesetzt.
Im Folgenden werden zunächst der verwendete Datensatz beschrieben. 
Anschließend wird der Aufbau des Netzwerks erläutert, welches die Grundlage für die nachfolgenden Untersuchungen bildet.

\section{Datensatz}
Für diese Arbeit wird der Datensatz "Brain Tumor MRI Dataset", welcher auf Kaggle veröffentlicht wurde, verwendet.~\cite{msoud_nickparvar_2021}
Dieser beinhaltet die vier Klassen: no Tumor, Glioma, Meningioma und Pituitary.
In dieser Arbeit wird die Klasse Pituitary nicht betrachtet, da die MRT-Aufnahmen überwiegend in der Sagittal Ebenen vorliegen, während die Bilder der anderen Klassen
hauptsächlich in der Axial Ebenen aufgenommen wurde.
Somit wären die Bilddaten nicht direkt vergleichbar.
Aufgeteilt ist der Datensatz in Trainingsdaten und Testdaten.
Die Anzahl der verwendeten Bilder sind in der Tabelle \ref{tab:daten} dargestellt. 
\begin{table}[H]
    \centering
    \begin{tabular}{c c c}
        \toprule
        Klasse      & Training samples & Test samples \\
        \midrule
        no Tumor    &    1595          & 405 \\
        Glioma      &    1321          & 300 \\
        Meningioma  &    1339          & 306 \\
        \bottomrule
  \end{tabular}
  \caption{Anzahl der verwendeten Trainings Bilder und Test Bilder.}
  \label{tab:daten}
\end{table}
\vspace{-2em}
Im Folgenden werden zwei unterschiedliche Klassifikationen durchgeführt.
Zunächst wird das CNN trainiert, sodass es zwischen der Klasse no Tumor und Tumor unterscheidet. Für die Klasse Tumor
werden die Daten der Glioma und Meningioma Klasse zusammengefasst.
Die zweite Klassifikation besteht darin, dass das CNN zwischen den Tumorarten Glioma und Meningioma unterscheidet.
Dabei wird die Meningioma Klasse als positiv und die Glioma Klasse als negativ definiert.

Da die MRT Bilder unterschiedliche Größen besitzen, werden diese zu Beginn auf $224 \times 224$ Pixel skaliert.
Zudem wird die Bilder in ein Array umgewandelt und normiert auf die Werte [0,1].

Für das Training des Netzwerkes werden die Trainingsdaten aufgeteilt. $\qty{80}{\%}$ der Daten, werden zum trainieren des Netzwerkes 
verwendet und $\qty{20}{\%}$ zur Validierung.
Die Aufteilung der Bilder bleibt für jeden Trainingsdurchgang gleich, sodass die Validierung stets auf denselben Daten basiert und die Bewertung der Modelle vergleichbar bleibt.

\section{Netzwerkarchitektur und Trainingsprozess}
Das verwendete Convolutional Neural Network besteht aus vier Convolutional Layers. Als Aktivierungsfunktion wird die ReLU-Funktion verwendet.
Zudem wird ein $3 \times 3$ Kernel mit jeweils ein Max-Pooling von der Größe $2 \times 2$ eingesetzt. 
In jeder Convolutional Schicht beträgt der Stride und das Padding den Wert 1.
Da es sich bei den MRT-Bildern um Graustufenbilder handelt, besitzt das Eingabebild einen Kanal. 
In der ersten Schicht werden 32 Filter verwendet.
Die Anzahl erhöht sich in jeder Schicht um den Faktor zwei.
Somit werden in der letzten Convolutional Schicht 128 Filter verwendet.
In der FC-Layer wird ein Dropout implementiert, um Overfitting zu vermeiden.

Beim Training des Netzwerkes, wird der Adam Optimizer verwendet. 
Als Verlustfunktion wird die Binary Cross-Entropy-Loss, gemäß der Formel \ref{eq:BCE}, genutzt.
Zudem werden alle zehn Epochen Checkpoints gesetzt und das Modell gespeichert.
Um Overfitting zu vermeiden, wird ein Early Stop implementiert. Wenn der Validation Loss sich über zehn Epochen nicht um $10^{-4}$
verbessert, wird das Training gestoppt und das Modell mit den niedrigsten Validation Loss wird gespeichert.
Mit diesem Modell werden die Daten getestet.

Zur Beurteilung der Leistungsfähigkeit des Klassifizierungsalgorithmus wird für jede Klassifikation die Accuracy, 
Sensitivity und Specificity, sowohl für die Validierung- und Testdaten, berechnet.
Die Anzahl der korrekt als zur positiven Klasse erkannten Fälle wird als True Positives (TP) bezeichnet, die der korrekt als zur negativen Klasse erkannten Fälle als True Negatives (TN).
Fälle, die fälschlicherweise als positiv klassifiziert werden, obwohl sie zur negativen Klasse gehören, nennt man False Positives (FP).
Dementsprechend bezeichnet man als False Negatives (FN) Fälle, die fälschlicherweise als negativ erkannt werden, obwohl sie tatsächlich zur positiven Klasse gehören.
Die Accuracy wird über
\begin{equation}
  Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
berechnet und gibt den Anteil an korrekt vorhergesagten Fällen an. 
Die Sensitivity beschreibt, wie viele Krankheitsfälle korrekt erkannt werden. 
Dies lässt sich über den Zusammenhang
\begin{equation}
  Sensitivity = \frac{TP}{TP + FN}
\end{equation}
beschreiben.
Die Specificity wird über die Formel
\begin{equation}
  Specificity = \frac{TN}{TN + FP}
\end{equation}
ermittelt und gibt den Anteil der korrekten Fälle an, bei dem keine Krankheit vorliegt. 
Für die Klassifikation zwischen Glioma und Meningioma wird wird die Meningioma Klasse als positiv und die Glioma Klasse als negativ definiert.

\section{Hyperparameter}\label{sec:Hyperparameter}
Um die Hyperparameter für beide Klassifikationen zu bestimmen, werden verschiedene Wert für die
Lernrate, Batch-Größe und den Dropout getestet.
Mittels Rastersuche werden die verschiedene Kombinationen der Parameter für das Training des Netzwerkes verwendet. 
Das Training wird jeweils maximal über 1000 Epochen ausgeführt.
Die getesteten Werte, werden in der Tabelle \ref{tab:Hypp} gezeigt.
\begin{table}[htbp]
    \centering
    {\small
    \begin{tabular}{c c}
        \toprule
        Hyperparameter     & Werte \\
        \midrule
        Batch Größe    & 16, 32, 64, 128   \\
        Dropout        & 0.2, 0.3, 0.4, 0.5 0.55   \\
        Lernrate       & 0.0001, 0.0005, 0.001, 0.005, 0.1   \\
        \bottomrule
  \end{tabular}}
  \caption{Die verschiedenen Hyperparameter mit ihren verwendeten Werten.}
  \label{tab:Hypp}
\end{table}
Anschließend werden die fünf Hyperparameter-Kombinationen ausgewählt, die den niedrigsten Validation Loss besitzen.
Dabei werden die Accuracy, Sensitivity und Specificity der Validierungs Daten verglichen und die beste Kombination der Hyperparameter, 
für die jeweilige Klassifizierung ausgewählt.  

\section{Reduktion der Trainingsdaten}\label{sec:Red1}
Um den Einfluss der Datensatzgröße auf den Klassifizierungsalgorithmus zu untersuchen, wird die Anzahl der verwendeten Trainingsdaten reduziert.
Mit den aus \ref{sec:Hyperparameter} bestimmten Hyperparameter wird im nächsten Schritt die Anzahl an Trainingsdaten reduziert.
Dabei bleibt die Anzahl an Validierungsdaten konstant.
Die Trainingsdaten werden in $\qty{10}{\%}$ Schritten reduziert. 
Das Netzwerk wird mit jeder Datensatzgröße separat trainiert und mit den Testdaten evaluiert. 
Aufgenommen wird die Accuracy, Sensitivity und Specificity.
Dies wird für jede Trainingsgröße zehnmal wiederholt.
Aus den gesamten Durchläufen wird der Mittelwert und die Standardabweichung der jeweiligen Metrik berechnet.

\section{Augmentation}
Um den Klassifizierungsalgorithmus robuster gegenüber variierender Trainingsdaten zu machen, wird eine Datenaugmentation eingesetzt.
Dabei können die Trainingsbilder transformiert werden, indem diese beispielsweise zufällig gespiegelt, gedreht oder zugeschnitten werden. 
Dadurch werden beim training immer leicht unterschiedliche Varianten der Bilder verwendet, um Overfitting entgegenzuwirken.~\cite{Yamashita2018}

Zur Augmentation wird eine Spiegelung der Bilder um ihre horizontal oder vertikale Achse hinzugefügt.
Beim Training wird zufällig gewählt, ob das Bild gespiegelt wird oder im Original verwendet wird.
Das Verfahren zur Untersuchung der Netzwerkleistung erfolgt analog zu Abschnitt \ref{sec:Red1}.    

\section{Reduzierung einer Sample Klasse}
Da bei seltenen Tumorarten die Datenmenge gering ist, wird der Einfluss auf die Leistung des Netzwerkes untersucht, 
bei der Reduktion der Daten einer Klasse.
Bei der Klassifikation zwischen Tumor und no Tumor, wird die Anzahl an Tumor-Bildern schrittweise reduziert, 
während die Anzahl an Bildern der no Tumor Klasse konstant bleibt.
Für die Klassifizierung zwischen Glioma und Meningioma wird analog die Anzahl an Glioma-Bildern reduziert, während die Anzahl an Meningioma-Bilder konstant bleibt.
Die Reduktion der Daten erfolgt in $\qty{10}{\%}$ Schritten. 

Aufgrund der Reduktion einer Klasse, entsteht ein unausgeglichener Datensatz.
Um dies auszugleichen, wird eine Gewichtung in die Verlustfunktion hinzugefügt.
Die Gewichtung der einzelnen Klassen $w_c$ über 
\begin{equation}
  w_c = \frac{1/n_c}{\sum_{k=1}^{c} 1/n_k}
\end{equation}
berechnet. Dabei beschreibt $n_c$ die Anzahl an Training samples der Klasse $c$.
Somit werden die Klassen gewichtet und die reduzierte Klasse wird stärker in der Loss-Funktion berücksichtigt.~\cite{pytorchCrossEntropy}

Das Trainieren und Testen des Modells wird jeweils zehnmal durchgeführt und anschließend der Mittelwert und die Standardabweichung der
Metriken berechnet.


