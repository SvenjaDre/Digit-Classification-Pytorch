\chapter{Ergebnisse}
In diesem Kapitel werden die Ergebnisse der verschiedenen Untersuchungen dargestellt, die in Kapitel \ref{sec:methodik} beschrieben wurden.
Zunächst wird die Leistung des Modells bei unterschiedlichen Datensatzgrößen für die Klassifikation zwischen Tumor und no Tumor untersucht.
Anschließend folgen die Ergebnisse zur Klassifikation zwischen Glioma und Meningioma

\section{Klassifizierung zwischen Tumor und no Tumor}
Zu Beginn wird das Modell mit verschiedenen Kombinationen von Hyperparametern trainiert, um geeignete Einstellungen für das weitere Vorgehen zu identifizieren.
Die Auswahl erfolgt auf Basis der Leistung auf dem Validierungsdatensatz.
Die besten Konfigurationen werden anschließend für die weiteren Trainingsdurchläufe verwendet.

\subsection{Hyperparameter}
Um die optimalen Hyperparameter zu bestimmen, wurde anhand der in Tabelle \ref{tab:Hypp} angegebenen Wertebereiche eine Rastersuche durchgeführt.
Dadurch wurden alle möglichen Kombinationen getestet.
Anschließend wurden die fünf Trainingsdurchläufe (Runs) mit dem niedrigsten Validation Loss betrachtet.
Der Verlauf des Validation Loss dieser fünf besten Runs ist in Abbildung \ref{fig:val_loss notu-tu} dargestellt.
%\vspace{-2em}
Die für die fünf Runs verwendeten Hyperparameter, sowie die ermittelten Werte für Accuracy, Sensitivity und Specificity auf den Validierungsdaten,
sind in der Tabelle \ref{tab:hyperp notu-tu} dargestellt.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]{plots/Val_loss_noTu_Tu.pdf}
  \caption{Verlauf des validation loss bei der Verwendung verschiedener Hyperparameter.}
  \label{fig:val_loss notu-tu}
\end{figure}
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccccccc}
            \toprule
            Runs & Batch Größe & Lernrate & Dropout & validation loss & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            1 & 128 & 0.005  & 0.55 & 0.072539 & 97.532 & 97.967 & 96.774 \\
            2 & 128 & 0.0005 & 0.5  & 0.073672 & 98.002 & 98.706 & 96.774 \\
            3 & 16  & 0.0001 & 0.5  & 0.076007 & 97.885 & 97.597 & 98.387 \\
            4 & 128 & 0.0005 & 0.4  & 0.080399 & 97.767 & 97.782 & 97.742 \\
            5 & 128 & 0.0005 & 0.5  & 0.080853 & 97.650 & 98.706 & 95.806 \\
            \bottomrule
        \end{tabular}
    }
  \caption{Die fünf Runs mit dem niedrigsten validation loss sowie deren verwendete Hyperparameter und aufgezeichnete Metriken.}
  \label{tab:hyperp notu-tu}
\end{table}
Die Werte für Accuracy, Sensitivity und Specificity liegen eng bei einander und schwanken nur geringfügig.
Auf Grund dessen, das die Validierungsergebnisse vergleichbar sind, werden für die weiteren Trainingsdurchläufen die Hyperparameter des Runs 1 verwendet. 

\subsection{Reduzierung der Trainingsdaten}
Das Netzwerk wird in diesem Abschnitt mit unterschiedlichen Datensatzgrößen trainiert und anschließend auf einen Testdatensatz angewendet.
Dabei wird die Accuracy, Sensitivity und Specificity zur Leistungsbeurteilung des Modells berechnet.
Diese Ergebnisse sind in Abbildung \ref{fig:reduzierung_trainingsdaten} sowie in Tabelle \ref{tab:reduzierung_trainingsdaten} dargestellt.
Da beobachtet wird, dass die Werte der Metriken bei 2723 gesunken sind, wurde zusätzlich das Netzwerk mit 2553, 2893 und 3234 
Training samples trainiert.
Es zeigt sich, dass die drei Metriken einen ähnlichen Verlauf aufweisen.
Die niedrigsten Werte werden bei 340 Training samples aufgenommen und steigen dann kontinuierlich mit der sample Anzahl an.
Ab 2042 verwendete samples zeigen die Werte der Accuracy, Sensitivity und Specificity nur noch geringe Änderungen.
Dabei schwankt die Accuracy im Bereich zwischen 2042 und 3404 Training samples zwischen \SI{93.12}{\%} und \qty{96.26}{\%}. 
Die Werte der Sensitivity variieren in diesem Bereich zwischen \SI{91.47}{\%} und \SI{94,62}{\%} und die der Specificity um \SI{97.41}{\%} und \SI{98.72}{\%}.
Es lässt sich somit feststellen, dass sich ab einer Trainingsdatengröße von 2042 samples eine Sättigung einstellt und dem Netzwerk genügend Daten zu Verfügung steht um zuverlässige Voraussagen zu treffen. 
Die Ergebnisse belegen, dass mit steigender Datensatzgröße eine Leistungssteigerung einhergeht.
Da jedoch die verfügbare Datenmenge in der Praxis begrenzt ist, wird im folgenden Abschnitt untersucht, inwiefern sich die Leistung des Modells durch die Verwendung von Augmentation verbessern lässt. 
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/2-Messungen-noTu-Tu_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:reduzierung_accuracy}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/2-Messungen-noTu-Tu_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:reduzierung_sensitivity}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/2-Messungen-noTu-Tu_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:reduzierung_specificity}
  \end{subfigure}
  \caption{Aufgenommene Metriken in Abhängigkeit der Verwendeten Trainingsdaten für die Klassifikation zwischen no Tumor und Tumor.}
  \label{fig:reduzierung_trainingsdaten}
\end{figure}
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccc|cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ & Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            340  & $86.21 \pm 0.44$ & $86.06 \pm 1.37 $ & $86.44 \pm 2.49$ & 2553 & $94.88 \pm 1.62$ & $93.80 \pm 1.75 $ & $96.49 \pm 1.96$ \\
            681  & $87.99 \pm 1.31$ & $87.54 \pm 2.29 $ & $88.67 \pm 3.29$ & 2723 & $93.12 \pm 1.12$ & $91.47 \pm 1.81 $ & $95.58 \pm 2.37$ \\ 
            1021 & $90.22 \pm 0.58$ & $88.60 \pm 1.01 $ & $92.64 \pm 1.80$ & 2893 & $95.42 \pm 1.54$ & $94.03 \pm 2.30 $ & $97.51 \pm 0.80$ \\
            1362 & $92.71 \pm 1.31$ & $91.14 \pm 1.83 $ & $95.06 \pm 1.86$ & 3064 & $94.75 \pm 1.55$ & $93.27 \pm 2.08 $ & $96.96 \pm 1.02$ \\ 
            1702 & $92.70 \pm 0.35$ & $90.28 \pm 0.78 $ & $96.32 \pm 0.68$ & 3234 & $94.61 \pm 1.11$ & $92.23 \pm 1.90 $ & $98.17 \pm 1.08$ \\
            2042 & $94.85 \pm 1.03$ & $93.14 \pm 1.34 $ & $97.41 \pm 1.40$ & 3404 & $96.26 \pm 1.39$ & $94.62 \pm 1.67 $ & $98.72 \pm 1.28$ \\ 
            2383 & $94.45 \pm 0.85$ & $92.94 \pm 1.66 $ & $96.72 \pm 0.56$ &      &                  &                   &                  \\
            \bottomrule
        \end{tabular}
    }
  \caption{Mittelwert und Standardabweichung der Metriken bei der Reduzierung der Training samples.}
  \label{tab:reduzierung_trainingsdaten}
\end{table}
\subsection{Augmentation}
Um den Einfluss der Augmentation auf die Leistung des Netzwerkes zu untersuchen, wird das Netzwerk für verschiedene Datensatzgrößen trainiert.
Dabei wird zufällig das Originalbild oder ein Bild verwendet, welches um seine horizontale oder vertikale Achse gespiegelt wird. 
Die Ergebnisse der Accuracy, Sensitivity und Specificity werden in Abhängigkeit der Training samples in Abbildung \ref{fig:augmentation_tu} dargestellt.
Die dargestellten Werte werden in der Tabelle \ref{tab:augm-tunotu} aufgeführt.
Zwischen 340 bis 2042 Samples, steigen die Accuracy und die Specificity konstant an und gehen anschließend in ein Plateau über.
Innerhalb des Plateaus schwankt die Accuracy zwischen \SI{94.25}{\percent} und \SI{96.43}{\percent}, während die Specificity Werte zwischen \SI{92.34}{\percent} und \SI{94.75}{\percent} annimmt.
Der Verlauf der Sensitivity unterscheidet sich leicht.
Sie steigt zunächst bis zu 1021 samples an und bleibt anschließend bis 1702 Samples konstant bei rund \SI{89}{\%}.
Danach steigt sie erneut an und variiert, von 2042 bis 3404 Training samples, zwischen \SI{92.34}{\%} und \SI{94.75}{\%}.\\
Diese Ergebnisse zeigen, dass die Augmentation bei kleineren und mittleren Datensatzgrößen nur einen geringen Einfluss auf die Modellleistung hat.
Bei der Verwendung von mittleren Datensatzgrößen bleibt die Sensitivity nahezu unverändert und die Accuracy und Specificity verbessern sich nur gering.
Erst bei größeren Datenmengen ist eine Verbesserung der Metriken zu erkennen. 
%Die Ergebnisse zeigen, dass die Augmentation ab einer Anzahl von 2042 Training samples einen Einfluss auf die Leistung besitzt.
%Somit hilft die Variation der Bilder das Modell etwas robuster gegenüber Veränderungen zu machen und zuverlässige Vorhersagen zu treffen.
%Bei kleineren Datenmenge hat dies kaum einen Einfluss um die Leistung zu erhöhen. 
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccc|cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ &
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            340  & $86.04 \pm 0.69$ & $85.97 \pm 1.27$ & $86.15 \pm 2.57$ & 2042 & $95.10 \pm 1.03$ & $93.81 \pm 1.95$ & $97.04 \pm 1.15$ \\
            680  & $88.43 \pm 0.70$ & $87.38 \pm 1.50$ & $90.00 \pm 2.84$ & 2382 & $94.57 \pm 0.93$ & $93.50 \pm 1.71$ & $96.17 \pm 1.19$ \\
            1021 & $90.01 \pm 0.64$ & $89.49 \pm 0.93$ & $90.79 \pm 1.10$ & 2723 & $94.25 \pm 1.17$ & $92.34 \pm 1.55$ & $97.11 \pm 1.25$ \\
            1361 & $91.59 \pm 0.94$ & $89.49 \pm 1.43$ & $94.74 \pm 2.04$ & 3063 & $95.73 \pm 1.44$ & $94.65 \pm 1.78$ & $97.33 \pm 1.66$ \\
            1702 & $92.43 \pm 0.84$ & $89.70 \pm 1.47$ & $96.52 \pm 0.62$ & 3404 & $96.43 \pm 1.49$ & $94.75 \pm 1.95$ & $98.94 \pm 1.03$ \\
            \bottomrule
        \end{tabular}
    }
    \caption{Mittelwert und Standardabweichung der Metriken bei Reduzierung der Training samples unter Verwendung von Augmentation.}
    \label{tab:augm-tunotu}
\end{table}
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/Augm-Messungen-noTu-Tu_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:augmentation_accuracy}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/Augm-Messungen-noTu-Tu_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:augmentation_sensitivity}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/Augm-Messungen-noTu-Tu_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:augmentation_specificity}
  \end{subfigure}
  \caption{Verlauf der Metriken bei unterschiedlichen Anzahl an Training samples, unter Verwendung von Augmentation, für die Klassifikation zwischen no Tumor und Tumor.}
  \label{fig:augmentation_tu}
\end{figure}

\subsection{Reduzierung der Tumor samples}
Für die Untersuchung der Netzwerkleistung bei Reduzierung einer Klasse, wurde die Anzahl an Tumor samples reduziert.
Der Verlauf der drei Metriken, sowie die Werte werden in der Abbildung \ref{fig:reduzierung_tumorsamples} und in der Tabelle \ref{tab:red_tu} dargestellt.
Die Accuracy steigt mit zunehmender Anzahl an samples bis zu maximal \SI{96.7458}{\percent} für 1702 Training samples.
Bei 1276 und 2128 samples sinkt sie auf ungefähr \SI{92}{\percent} ab. 
Die Sensitivity bleibt von 212 bis 851 Tumor samples konstant bei rund \SI{90}{\%}.
Danach steigt sie leicht an und erreicht bei 1915 verwendeten Bildern einen Wert von \SI{95.15}{\%}.
Auch hier sinkt bei der Verwendung aller Tumor Bilder die Sensitivity wieder ab.
Die Specificity steigt mit höherer sample Anzahl und konvergiert gegen rund \SI{100}{\%}.
Bei 212 und 1276 Tumor samples tritt eine hohe Standardabweichung für die Specificity und Accuracy auf.
Zusätzlich kommt es auch bei 2128, für die Accuracy und für die Sensitivity, zu einer große Abweichung. 
In Runs bei denen 212 und 1276 Tumor samples verwendet wurden, lag die Specificity, 
sowie bei 2128 Tumor samples die Sensitivity bei 0.
Dies kommt dadurch, dass anstelle des Globalen Minimum ein Lokales Minimum der Verlustfunktion ermittelt wurde.
In diesem Lokalen Minimum wurde, bei 212 und 1276 Training samples, alle Testdaten als Tumor Bilder Vorhergesagt, wodurch die Specificity \SI{0}{\%} beträgt.
Bei 2128 Training samples beträgt die Sensitivity \SI{0}{\%}, da aufgrund des Lokalen Minimums alle Daten als no Tumor klassifiziert werden.
Damit kommt es zu einer geringeren Accuracy und im Mittel ergibt sich dann die großen Standardabweichungen.
Die Untersuchung zeigt, dass durch das Reduzieren der Tumor Klasse es zu einem Leistungsabfall führen kann.
Ab einer Anzahl von 1489 Tumor samples erreicht das Modell eine stabile und zuverlässige Leistung.
Die Anzahl an verwendeten no Tumor Samples im Vergleich beträgt im Training 1279. 
Daraus lässt sich schließen, dass eine möglichst ausgeglichene Klassenverteilung notwendig ist, um eine hohe Leistung zu erreichen.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/neu Reduzierung-Tu + Balance_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:reduzierung_tu_accuracy}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/neu Reduzierung-Tu + Balance_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:reduzierung_tu_sensitivity}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/neu Reduzierung-Tu + Balance_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:reduzierung_tu_specificity}
  \end{subfigure}
  \caption{Metriken bei Reduktion der Tumor samples.}
  \label{fig:reduzierung_tumorsamples}
\end{figure}
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccc|cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ &
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            212  & $81.87 \pm 8.11$  & $89.79 \pm 3.89$  & $70.02 \pm 25.44$ & 1276 & $91.92 \pm 11.27$ & $94.41 \pm 2.58$  & $88.20 \pm 31.00$ \\
            425  & $89.80 \pm 1.26$  & $89.16 \pm 1.79$  & $90.77 \pm 2.85$  & 1489 & $96.10 \pm 0.69$  & $94.69 \pm 0.95$  & $98.22 \pm 1.18$  \\
            638  & $90.34 \pm 2.32$  & $89.59 \pm 1.70$  & $91.46 \pm 6.22$  & 1702 & $96.75 \pm 1.08$  & $95.12 \pm 1.50$  & $99.19 \pm 0.69$  \\
            851  & $93.67 \pm 1.15$  & $91.83 \pm 1.51$  & $96.42 \pm 2.03$  & 1915 & $96.65 \pm 1.12$  & $95.15 \pm 1.24$  & $98.89 \pm 1.11$  \\
            1064 & $94.20 \pm 0.85$  & $92.71 \pm 1.56$  & $96.44 \pm 1.35$  & 2128 & $92.04 \pm 18.27$ & $87.01 \pm 30.58$ & $99.56 \pm 0.36$  \\
            \bottomrule
        \end{tabular}
    }
    \caption{Mittelwert und Standardabweichung der Metriken bei der Reduzierung der Tumor Klasse.}
    \label{tab:red_tu}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klassifizierung zwischen Glioma und Meningioma}
Für die Untersuchung der Leistung des Netzwerkes für eine Klassifikation zwischen zwei Tumorarten werden die Untersuchungen analog zur Untersuchung 
zwischen Tumor und no Tumor durchgeführt
Für die Klassifizierung zwischen Glioma und Meningioma werden zu begin die Hyperparameter ermittelt, mit denen die nachfolgenden
Trainingsdurchläufe verwendet werden. 
Die Erfolg analog zur Ermittlung der Hyperparameter der vorherigen Klassifikation.
\subsection{Hyperparameter}
Für die Ermittlung der Hyperparameter werden die fünf Runs mit den niedrigsten Validation loss, aus allen möglichen Kombination der Wertebereiche der Hyperparameter, betrachtet.
Der Verlauf wird in der Abbildung \ref{fig:val_loss gli-men} dargestellt.
Die dazugehörigen Parameter und die Accuracy, Sensitivity und Specificity des Validierung Datensatzes werden in der Tabelle \ref{tab:hyperp-gli men} aufgelistet.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]{plots/Val_loss_Gli_Men.pdf}
  \caption{Darstellung des validation loss bei der Verwendung verschiedener Hyperparameter.}
  \label{fig:val_loss gli-men}
\end{figure}
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccccccc}
            \toprule
            Runs & Batch Größe & Lernrate & Dropout & Validation Loss & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            1 & 128 & 0.01  & 0.55 & 0.18943 & 92.293 & 95.402 & 89.299 \\
            2 & 64  & 0.005 & 0.3  & 0.22499 & 93.233 & 96.935 & 89.668 \\
            3 & 16  & 0.0005& 0.55 & 0.23146 & 93.985 & 92.720 & 95.203 \\
            4 & 16  & 0.005 & 0.5  & 0.23453 & 92.669 & 95.402 & 90.037 \\
            5 & 16  & 0.0005& 0.5  & 0.23829 & 93.421 & 94.253 & 92.620 \\
            \bottomrule
        \end{tabular}
    }
  \caption{Die fünf Runs mit dem niedrigsten validation loss sowie deren verwendete Hyperparameter und aufgezeichneten Metriken.}
  \label{tab:hyperp-gli men}
\end{table}
Die Accuracy beträgt in allen fünf Runs zwischen \SI{92}{\%} und \SI{93}{\%}. Die Schwankungen zwischen ihnen ist somit nur geringfügig.
Die Werte der Sensitivity schwanken zwischen ungefähr \SI{92}{\%} und rund \SI{97}{\%}.
Und auch die Specificity zeigt eine große Schwankung, welche zwischen \SI{89}{\%} und \SI{95}{\%} liegt.
Der erste Run besitzt zwar den niedrigsten validation loss, jedoch auch die niedrigste Accuracy und Specificity.
Der höchste Wert der Accuracy und Specificity tritt bei Run 3 auf
Aufgrund dessen werden in den folgenden Trainingsdurchläufen die Hyperparameter von Run 3 verwendet.
\subsection{Reduzierung der Trainingsdaten}
Zur Untersuchung des Einflusses der Datensatzgröße auf die Modellleistung wurde das Netzwerk mit unterschiedlich großen Trainingsmengen trainiert. 
Bewertet wurde die Leistung anhand der Metriken Accuracy, Sensitivity und Specificity.
In Abbildung \ref{fig:gli-men-reduktion} ist der Verlauf der Accuracy, Sensitivity und Specificity bei der Reduktion der Training samples dargestellt.
Die dazu gehörigen Werte werden in der Tabelle \ref{tab:Red-gli-men} aufgelistet.
Alle drei Metriken zeigen, dass sie mit zunehmender Anzahl an Training samples steigt. 
Bei 851 Training samples sinken die Werte etwas, bevor sie anschließend wieder ansteigen.
Die Accuracy erhöht sich von \SI{76.42}{\percent}, bei 231 Training samples auf \SI{92.31}{\percent} bei 2128 Training samples.
Die Sensitivity steigt bis 1702 Training samples auf \SI{91.86}{\%} an und bleibt anschließend weitgehend konstant zwischen \SI{91.14}{\%} und \SI{92.55}{\%}.
Die Specificity nimmt bis 1064 Training samples zu und bleibt bis 1277 konstant. 
Danach sinkt diese kurzzeitig etwas und steigt anschließend wieder an. 
Ab 1915 Training samples bleibt die Specificity stabil bei ungefähr \SI{92}{\%}.
Für die Sensitivity deutet sich ab 1702 und bei der Specificity ab 1915 Training samples der Anfang einer Sättigung an.
Die Ergebnisse zeigen, dass mit zunehmender Anzahl an Training samples die Leistung zu nimmt.
Eine eindeutige Sättigung stellt sich nicht ein, womit nicht genau gesagt werden kann ob die Datenmenge ausreicht für die optimale Leistung. 
Da die Datenmenge begrenzt ist, wird im folgenden Abschnitt untersucht, inwiefern die Verwendung von Augmentation einen Einfluss auf die Modellleistung besitzt. 
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccc|cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ &
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            231  & $76.42 \pm 0.51$ & $78.46 \pm 3.83$ & $74.33 \pm 3.49$ & 1277 & $87.72 \pm 0.65$ & $88.17 \pm 2.70$ & $87.27 \pm 2.50$ \\
            426  & $78.66 \pm 0.70$ & $80.20 \pm 4.14$ & $77.10 \pm 2.98$ & 1490 & $88.12 \pm 0.89$ & $90.16 \pm 1.58$ & $86.03 \pm 2.78$ \\
            683  & $83.53 \pm 1.27$ & $83.17 \pm 3.83$ & $83.90 \pm 2.49$ & 1702 & $90.66 \pm 0.59$ & $91.86 \pm 1.17$ & $89.43 \pm 1.40$ \\
            851  & $81.83 \pm 1.29$ & $82.09 \pm 2.38$ & $81.57 \pm 2.33$ & 1915 & $91.67 \pm 0.92$ & $91.14 \pm 2.14$ & $92.20 \pm 0.76$ \\
            1064 & $87.11 \pm 1.25$ & $86.67 \pm 3.78$ & $87.57 \pm 2.60$ & 2128 & $92.31 \pm 0.83$ & $92.55 \pm 1.65$ & $92.07 \pm 1.43$ \\
            \bottomrule
        \end{tabular}
    }
    \caption{Mittelwert und Standardabweichung für die Reduzierung der Training samples.}
    \label{tab:Red-gli-men}
\end{table}
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/3-Messungen-Gli-Men_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:gli-men-acc}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/3-Messungen-Gli-Men_Sensitivity_mean.pdf}
    \caption{Sensitivität}
    \label{fig:gli-men-sens}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/3-Messungen-Gli-Men_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:gli-men-spec}
  \end{subfigure}
  \caption{Verlauf der Metriken bei der Reduzierung der Training samples für die Klassifikation zwischen Glioma und Meningioma.}
  \label{fig:gli-men-reduktion}
\end{figure}
%\vspace{-3.5em}
\subsection{Augmentation}
%\vspace{-0.5em}
Unter Verwendung von Augmentation wurden die Training samples reduziert.
Der Verlauf der Metriken ist in der Abbildung \ref{fig:gli-men-augm} dargestellt,
die entsprechenden Werte sind in der Tabelle \ref{tab:gli-men-augm} zu finden.
Die Accuracy steigt mit zunehmender Anzahl an Training samples an.
Zu beginn liegt sie bei \SI{75.87}{\percent} für 212 samples. 
Bei der Nutzung aller verfügbaren Trainingsdaten erreicht sie einen Wert von \SI{92.19}{\percent}.
Die Sensitivity nimmt zunächst bis 425 Bildern zu, sinkt anschließend etwas bei 638 Samples, steigt danach jedoch wieder an.
Ab 1702 samples bleibt sie weitgehend konstant bei \SI{91.01}{\%}, bevor sie bei 2128 Training samples auf \SI{92.61} ansteigt. 
Der Anstieg der Specificity erfolgt konstant bis 1064 Training sample und flacht anschließend ab.
Bei 2128 Samples wird eine Specificity von \SI{91.77}{\%} erreicht.\\
Die Verwendung von Augmentation hat für die Accuracy und Sensitivity kaum einen Einfluss, da die Werte kaum eine Verbesserung zeigen.
Für die Specificity kommt es in Bereich zwischen 1064 und 1702 Training samples ene leichten Verbesserung, sowie stabileren Verlauf zu erkennen.
%Es lässt sich somit feststellen, dass die hier eingesetzte Augmentation bei kleineren Trainingsdatensätzen keine signifikante Leistungsverbesserung bewirkt. 
%Der Effekt ist nur in einem mittleren Bereich der Datensatzgröße erkennbar und betrifft die Stabilität der Specificity.
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccc|cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ &
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            212  & $75.87 \pm 0.61$ & $78.01 \pm 5.64$ & $ 73.70 \pm 6.56$ & 1276 & $87.99 \pm 0.85$ & $87.68 \pm 1.80$ & $ 88.30 \pm 2.02$ \\
            425  & $79.72 \pm 0.44$ & $81.99 \pm 1.47$ & $ 77.40 \pm 1.62$ & 1489 & $89.01 \pm 1.19$ & $88.86 \pm 2.21$ & $ 89.17 \pm 1.96$ \\
            638  & $80.69 \pm 0.57$ & $79.58 \pm 1.70$ & $ 81.83 \pm 0.85$ & 1702 & $90.71 \pm 0.56$ & $91.01 \pm 2.09$ & $ 90.40 \pm 1.75$ \\
            851  & $81.55 \pm 0.98$ & $81.70 \pm 2.28$ & $ 81.40 \pm 1.34$ & 1915 & $91.27 \pm 1.20$ & $91.01 \pm 1.82$ & $ 91.53 \pm 1.21$ \\
            1064 & $86.45 \pm 0.82$ & $85.26 \pm 2.39$ & $ 87.67 \pm 1.91$ & 2128 & $92.19 \pm 0.88$ & $92.61 \pm 1.39$ & $ 91.77 \pm 1.23$ \\
            \bottomrule
        \end{tabular}
    }
    \caption{Mittelwert und Standardabweichung der drei Metriken bei Reduzierung der Training samples unter Verwendung von Augmentation für die Klassifikation zwischen Glioma und Meningioma.}
    \label{tab:gli-men-augm}
\end{table}
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Augm-Gli-Men_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:augm-acc}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Augm-Gli-Men_Sensitivity_mean.pdf}
    \caption{Sensitivität}
    \label{fig:augm-sens}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Augm-Gli-Men_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:augm-spec}
  \end{subfigure}
  \caption{Verlauf der Metriken bei Reduzierung der Training samples unter Verwendung von Augmentation für die Klassifikation zwischen Glioma und Meningioma.}
  \label{fig:gli-men-augm}
\end{figure}
\subsection{Reduzierung der Glioma sample}
Um den Einfluss der Modellleistung bei Reduzierung einer Klasse zu untersuchen, wurde die Anzahl an Glioma samples schrittweise reduziert.
Die Meningioma samples konstant gehalten bei 1072.
Für die Klassifizierung wurde die Meningioma Klasse als positiv und die Glioma Klasse als negativ definiert. 
Zur Beurteilung werden die Accuracy, Sensitivity und die Specificity berechnet.
Der Verlauf der Metriken ist in der Abbildung \ref{fig:gli-men-gliored} dargestellt.
In der Tabelle \ref{tab:red-gli} sind die dargestellten Mittelwerte und Standardabweichungen aufgeführt. 
Es ist zu erkennen, dass die Accuracy und die Specificity zunächst bis zu 317 Glioma sample ansteigen und anschließend etwas leicht abfallen,
bevor sie mit zunehmender Anzahl erneut zunehmen. 
Die Accuracy wird ab 739 Glioma samples nahezu konstant bei etwa \SI{91}{\percent} und steigt bei 1057 Sample auf \SI{93.75}{\percent} an.
Die Specificity schwankt im Bereich zwischen 739 und 951 Glioma samples zwischen \SI{89.67}{\%} \SI{91.77}{\%}.
Bei Verwendung aller verfügbaren Glioma samples erreicht sie einen Wert von \SI{93.07}{\%}.
Die Sensitivity beträgt bei nur 105 verwendeten Glioma samples einen Wert von \SI{80.56}{\%}.
Anschließende steigt sie deutlich an und schwankt im Bereich zwischen 211 und 951 Glioma samples zwischen \SI{89.12}{\%} und \SI{91.93}{\%}. 
Zum Schluss steigt sie bei 1057 Beispielen weiter auf \SI{94.41}{\%}.
Die Ergebnisse zeigen, dass mit geringerer Anzahl an Glioma sample zu einem Leistungsabfall kommt.
Die Sensitivity gibt die Fähigkeit des Modells an die Positive Klasse, in diesem Fall die Meningioma Klasse, zu erkenne.
Da diese in der Untersuchung konstant gehalten werden, kann das Modell zwischen 211 und 951 Glioma samples eine relative konstante Leistung erbringen, diese zu erkennen.
Mit einer höheren Anzahl an Glioma sample steigt diese jedoch weiter an und auch die Specificity, also die Fähigkeit die Glioma Fälle zu erkennen.
Für die Accuracy und Specificity lässt sich ab 845 Glioma samples der Ansatz einer Sättigung erkennen. 
\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Reduzierung-Gli + Balnce_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:gli-red-acc}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Reduzierung-Gli + Balnce_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:gli-red-sens}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Reduzierung-Gli + Balnce_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:gli-red-spec}
  \end{subfigure}
  \caption{Verlauf der drei Metriken für die Reduzierung der Glioma Klasse.}
  \label{fig:gli-men-gliored}
\end{figure}
\begin{table}[htbp]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccc|cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ &
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            105  & $78.94 \pm 1.51$ & $80.56 \pm 4.81$ & $ 77.30 \pm 3.20$ & 634  & $89.34 \pm 2.32$ & $91.34 \pm 2.35$ & $ 87.30 \pm 3.67$ \\
            211  & $84.80 \pm 1.28$ & $89.12 \pm 3.88$ & $ 80.40 \pm 4.52$ & 739  & $90.46 \pm 1.20$ & $91.24 \pm 2.53$ & $ 89.67 \pm 3.01$ \\
            317  & $86.62 \pm 1.75$ & $90.52 \pm 2.78$ & $ 82.63 \pm 4.04$ & 845  & $91.09 \pm 1.49$ & $90.42 \pm 2.30$ & $ 91.77 \pm 2.28$ \\
            422  & $85.68 \pm 1.39$ & $89.41 \pm 4.09$ & $ 81.87 \pm 3.72$ & 951  & $91.04 \pm 1.83$ & $91.93 \pm 1.57$ & $ 90.13 \pm 3.95$ \\
            528  & $87.10 \pm 1.86$ & $90.23 \pm 2.66$ & $ 83.90 \pm 3.52$ & 1057 & $93.75 \pm 1.69$ & $94.41 \pm 1.70$ & $ 93.07 \pm 2.35$ \\
            \bottomrule
        \end{tabular}
    }
    \caption{Mittelwert und Standardabweichung der Metriken für die Reduzierung der Glioma samples.}
    \label{tab:red-gli}
\end{table}






