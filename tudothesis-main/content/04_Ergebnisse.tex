\chapter{Ergebnisse}
In diesem Kapitel werden die Ergebnisse der verschiedenen Untersuchungen dargestellt, die in Kapitel \ref{sec:methodik} beschrieben wurden.
Zunächst wird die Leistung des Modells bei unterschiedlichen Datensatzgrößen für die Klassifikation zwischen Tumor und no Tumor untersucht.
Anschließend folgen die Ergebnisse zur Klassifikation zwischen Glioma und Meningioma

\section{Klassifizierung zwischen Tumor und no Tumor}
Zu Beginn wird das Modell mit verschiedenen Kombinationen von Hyperparametern trainiert, um geeignete Einstellungen für das weitere Vorgehen zu identifizieren.
Die Auswahl erfolgt auf Basis der Leistung auf dem Validierungsdatensatz.
Die besten Konfigurationen werden anschließend für die weiteren Trainingsdurchläufe verwendet.

\subsection{Hyperparameter}
Um die optimalen Hyperparameter zu bestimmen, wurde anhand der in Tabelle \ref{tab:Hypp} angegebenen Wertebereiche eine Rastersuche durchgeführt.
Dadurch wurden alle möglichen Kombinationen getestet.
Anschließend wurden die fünf Trainingsdurchläufe (Runs) mit dem niedrigsten Validation Loss betrachtet.
Der Verlauf des Validation Loss dieser fünf besten Runs ist in Abbildung \ref{fig:val_loss notu-tu} dargestellt.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]{plots/Val_loss_noTu_Tu.pdf}
  \caption{Verlauf des validation loss bei der Verwendung verschiedener Hyperparameter.}
  \label{fig:val_loss notu-tu}
\end{figure}
\vspace{-2em}
Die für die fünf Runs verwendeten Hyperparameter, sowie die ermittelten Werte für Accuracy, Sensitivity und Specificity auf den Validierungsdaten,
sind in der Tabelle \ref{tab:hyperp notu-tu} dargestellt.
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccccccc}
            \toprule
            Runs & Batch Größe & Lernrate & Dropout & validation loss & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            1 & 128 & 0.005  & 0.55 & 0.072539 & 97.532 & 97.967 & 96.774 \\
            2 & 128 & 0.0005 & 0.5  & 0.073672 & 98.002 & 98.706 & 96.774 \\
            3 & 16  & 0.0001 & 0.5  & 0.076007 & 97.885 & 97.597 & 98.387 \\
            4 & 128 & 0.0005 & 0.4  & 0.080399 & 97.767 & 97.782 & 97.742 \\
            5 & 128 & 0.0005 & 0.5  & 0.080853 & 97.650 & 98.706 & 95.806 \\
            \bottomrule
        \end{tabular}
    }
  \caption{Die fünf Runs mit dem niedrigsten validation loss sowie deren verwendete Hyperparameter und aufgezeichnete Metriken.}
  \label{tab:hyperp notu-tu}
\end{table}
Die Werte für Accuracy, Sensitivity und Specificity liegen eng bei einander und schwanken nur geringfügig.
Auf Grund dessen, das die Validierungsergebnisse vergleichbar sind, werden für die weiteren Trainingsdurchläufen die Hyperparameter des Runs 1 verwendet. 

\subsection{Reduzierung der Trainingsdaten}
Das Netzwerk wird mit unterschiedlichen Datensatzgrößen trainiert und auf einen Testdatensatz angewendet, bei dem die Accuracy, Sensitivity und Specificity berechnet wird.
Da beobachtet wurde, dass die Werte der Metriken bei 2723 gesunken sind, wurde zusätzlich das Netzwerk mit 2553, 2893 und 3234 
Training samples trainiert.
Die Mittelwerte und Standardabweichung der Metriken wurden in Abhängigkeit von den Training samples dargestellt.
Diese Ergebnisse sind in Abbildung \ref{fig:reduzierung_trainingsdaten} sowie Tabelle \ref{tab:reduzierung_trainingsdaten} zusammengefasst.
Es ist zu erkennen, dass die drei Metriken einen ähnlichen Verlauf aufweisen.
Die niedrigsten Werte werden bei 340 Training samples aufgenommen und steigen dann kontinuierlich mit der sample Anzahl an.
Ab 2042 verwendete samples zeigen die Werte der Accuracy, Sensitivity und Specificity nur noch geringe Änderungen.
Dabei schwankt die Accuracy im Bereich zwischen 2042 und 3404 Training samples zwischen $\qty{93.1157}{\%}$ und $\qty{96.2611}{\%}$. 
Die Werte der Sensitivity variieren in diesem Bereich zwischen 0,9147 und 0,9462 und die der Specificity um \SI{0,9741}{} und \SI{0,9872}{}.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/2-Messungen-noTu-Tu_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:reduzierung_accuracy}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/2-Messungen-noTu-Tu_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:reduzierung_sensitivity}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/2-Messungen-noTu-Tu_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:reduzierung_specificity}
  \end{subfigure}
  \caption{Aufgenommene Metriken in Abhängigkeit der Verwendeten Trainingsdaten für die Klassifikation zwischen no Tumor und Tumor.}
  \label{fig:reduzierung_trainingsdaten}
\end{figure}
\begin{table}[H]
    \centering
    {\small
        \begin{tabular}{cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            340  & $86.21 \pm 0.44$ & $86.06 \pm 1.37 $ & $86.44 \pm 2.49$\\
            681  & $87.99 \pm 1.31$ & $87.54 \pm 2.29 $ & $88.67 \pm 3.29$\\
            1021 & $90.22 \pm 0.58$ & $88.60 \pm 1.01 $ & $92.64 \pm 1.80$\\
            1362 & $92.71 \pm 1.31$ & $91.14 \pm 1.83 $ & $95.06 \pm 1.86$\\
            1702 & $92.70 \pm 0.35$ & $90.28 \pm 0.78 $ & $96.32 \pm 0.68$\\
            2042 & $94.85 \pm 1.03$ & $93.14 \pm 1.34 $ & $97.41 \pm 1.40$\\
            2383 & $94.45 \pm 0.85$ & $92.94 \pm 1.66 $ & $96.72 \pm 0.56$\\
            2553 & $94.88 \pm 1.62$ & $93.80 \pm 1.75 $ & $96.49 \pm 1.96$\\
            2723 & $93.12 \pm 1.12$ & $91.47 \pm 1.81 $ & $95.58 \pm 2.37$\\
            2893 & $95.42 \pm 1.54$ & $94.03 \pm 2.30 $ & $97.51 \pm 0.80$\\
            3064 & $94.75 \pm 1.55$ & $93.27 \pm 2.08 $ & $96.96 \pm 1.02$\\
            3234 & $94.61 \pm 1.11$ & $92.23 \pm 1.90 $ & $98.17 \pm 1.08$\\
            3404 & $96.26 \pm 1.39$ & $94.62 \pm 1.67 $ & $98.72 \pm 1.28$\\ 
            \bottomrule
        \end{tabular}
    }
  \caption{Mittelwert und Standardabweichung der Metriken bei der Reduzierung der Training samples.}
  \label{tab:reduzierung_trainingsdaten}
\end{table}

\subsection{Augmentation}
Das Netzwerk wurde für verschiedene Datensatzgrößen trainiert, wobei beim Training Augmentation angewendet wurde.
Die Accuracy, Sensitivity und Specificity werden in Abhängigkeit der Training samples in Abbildung \ref{fig:augmentation_tu} abgebildet und
die dargestellten Werte werden in der Tabelle \ref{tab:augm-tunotu} aufgezeigt.
Von 340 bis 2042 Samples, steigt die Accuracy und die Specificity konstant an und geht anschließend in Plateau über.
Die Accuracy variieren innerhalb des Plateaus zwischen \SI{94.2532}{\percent} und \SI{96.4293}{\percent}. 
Die Specificity schwankt ab 2042 Training samples zwischen \SI{0.9234}{} und \SI{0.9475}{}.
Die Sensitivity steigt nur bis zu 1021 samples kontinuierlich an und bleibt bis zu 1702 Samples konstant bei ungefähr \SI{0,89}{}.
Danach steigt sie wieder an und schwankt, von 2042 bis 3404 Training samples, zwischen \SI{0.9234}{} und \SI{0.9475}{}. 
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/Augm-Messungen-noTu-Tu_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:augmentation_accuracy}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/Augm-Messungen-noTu-Tu_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:augmentation_sensitivity}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/Augm-Messungen-noTu-Tu_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:augmentation_specificity}
  \end{subfigure}
  \caption{Verlauf der Metriken bei unterschiedlichen Anzahl an Training samples, unter Verwendung von Augmentation, für die Klassifikation zwischen no Tumor und Tumor.}
  \label{fig:augmentation_tu}
\end{figure}
\begin{table}[H]
    \centering
    {\small
        \begin{tabular}{cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            340  & $86.04 \pm 0.69$ & $85.97 \pm 1.27$ & $86.15 \pm 2.57$\\
            680  & $88.43 \pm 0.70$ & $87.38 \pm 1.50$ & $90.00 \pm 2.84$\\
            1021 & $90.01 \pm 0.64$ & $89.49 \pm 0.93$ & $90.79 \pm 1.10$\\
            1361 & $91.59 \pm 0.94$ & $89.49 \pm 1.43$ & $94.74 \pm 2.04$\\
            1702 & $92.43 \pm 0.84$ & $89.70 \pm 1.47$ & $96.52 \pm 0.62$\\
            2042 & $95.10 \pm 1.03$ & $93.81 \pm 1.95$ & $97.04 \pm 1.15$\\
            2382 & $94.57 \pm 0.93$ & $93.50 \pm 1.71$ & $96.17 \pm 1.19$\\
            2723 & $94.25 \pm 1.17$ & $92.34 \pm 1.55$ & $97.11 \pm 1.25$\\
            3063 & $95.73 \pm 1.44$ & $94.65 \pm 1.78$ & $97.33 \pm 1.66$\\
            3404 & $96.43 \pm 1.49$ & $94.75 \pm 1.95$ & $98.94 \pm 1.03$\\
            \bottomrule
        \end{tabular}}
  \caption{Mittelwert und Standardabweichung der Metriken bei Reduzierung der Training samples unter Verwendung von Augmentation.}
  \label{tab:augm-tunotu}
\end{table}

\subsection{Reduzierung der Tumor samples}
Für die Untersuchung der Netzwerkleistung bei Reduzierung einer Klasse, wurde die Anzahl an Tumor samples reduziert.
Der Verlauf der drei Metriken, sowie die Werte werden in der Abbildung \ref{fig:reduzierung_tumorsamples} und in der Tabelle \ref{tab:red_tu} dargestellt.
Die Accuracy steigt mit zunehmender Anzahl an samples bis zu maximal \SI{96.7458}{\percent} für 1702 Training samples.
Bei 1276 und 2128 samples sinkt sie auf ungefähr \SI{92}{\percent} ab. 
Die Sensitivity bleibt von 212 bis 851 Tumor samples konstant bei ca. \SI{0.9}{}.
Danach steigt sie leicht an und erreicht bei 1915 verwendeten Bildern einen Wert von \SI{0.9515}{}.
Auch hier sinkt bei der Verwendung aller Tumor Bilder die Sensitivity wieder ab.
Die Specificity steigt mit höherer sample Anzahl und konvergiert gegen \SI{1.0}.
Bei 212 und 1276 Tumor samples tritt eine hohe Standardabweichung für die Specificity und Accuracy auf.
Zusätzlich kommt es auch bei 2128, für die Accuracy und für die Sensitivity, zu einer große Abweichung
Bei den Klassengrößen 
In Runs bei denen 212 und 1276 Tumor samples verwendet wurden, lag die Specificity, 
sowie bei 2128 Tumor samples die Sensitivity bei 0.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/neu Reduzierung-Tu + Balance_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:reduzierung_tu_accuracy}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/neu Reduzierung-Tu + Balance_Sensitivity_mean.pdf}
    \caption{Sensitivity}
    \label{fig:reduzierung_tu_sensitivity}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{plots/neu Reduzierung-Tu + Balance_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:reduzierung_tu_specificity}
  \end{subfigure}
  \caption{Metriken bei Reduktion der Tumor samples.}
  \label{fig:reduzierung_tumorsamples}
\end{figure}
\begin{table}[H]
    \centering
     {\small
        \begin{tabular}{cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            212  & $81.87 \pm 8.11$ & $89.79 \pm 3.89$ & $ 70.02 \pm 25.44$\\
            425  & $89.80 \pm 1.26$ & $89.16 \pm 1.79$ & $ 90.77 \pm 2.85$\\
            638  & $90.34 \pm 2.32$ & $89.59 \pm 1.70$ & $ 91.46 \pm 6.22$\\
            851  & $93.67 \pm 1.15$ & $91.83 \pm 1.51$ & $ 96.42 \pm 2.03$\\
            1064 & $94.20 \pm 0.85$ & $92.71 \pm 1.56$ & $ 96.44 \pm 1.35$\\
            1276 & $91.92 \pm 11.27$& $94.41 \pm 2.58$ & $ 88.20 \pm 31.00$\\
            1489 & $96.10 \pm 0.69$ & $94.69 \pm 0.95$ & $ 98.22 \pm 1.18$\\
            1702 & $96.75 \pm 1.08$ & $95.12 \pm 1.50$ & $ 99.19 \pm 0.69$\\
            1915 & $96.65 \pm 1.12$ & $95.15 \pm 1.24$ & $ 98.89 \pm 1.11$\\
            2128 & $92.04 \pm 18.27$& $87.01 \pm 30.58$ &$ 99.56 \pm 0.36$\\
            \bottomrule
        \end{tabular}}
  \caption{Mittelwert und Standardabweichung der Metriken bei der Reduzierung der Tumor Klasse.}
  \label{tab:red_tu}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klassifizierung zwischen Glioma und Meningioma}
Für die Klassifizierung zwischen Glioma und Meningioma werden zu begin die Hyperparameter ermittelt, mit denen die nachfolgenden
Trainingsdurchläufe verwendet werden. 
Die Erfolg analog zur Ermittlung der Hyperparameter der vorherigen Klassifikation.
\subsection{Hyperparameter}
Für die Ermittlung der Hyperparameter werden die fünf Runs mit den niedrigsten Validation loss betrachtet.
Der Verlauf wird in der Abbildung \ref{fig:val_loss gli-men} dargestellt.
Die dazugehörigen Parameter und die Accuracy, Sensitivity und Specificity des Validierung Datensatzes werden in der Tabelle \ref{tab:hyperp-gli men} aufgelistet.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]{plots/Val_loss_Gli_Men.pdf}
  \caption{Darstellung des validation loss bei der Verwendung verschiedener Hyperparameter.}
  \label{fig:val_loss gli-men}
\end{figure}
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{cccccccc}
            \toprule
            Runs & Batch Größe & Lernrate & Dropout & Validation Loss & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$ \\
            \midrule
            1 & 128 & 0.01  & 0.55 & 0.18943 & 92.293 & 95.402 & 89.299 \\
            2 & 64  & 0.005 & 0.3  & 0.22499 & 93.233 & 96.935 & 89.668 \\
            3 & 16  & 0.0005& 0.55 & 0.23146 & 93.985 & 92.720 & 95.203 \\
            4 & 16  & 0.005 & 0.5  & 0.23453 & 92.669 & 95.402 & 90.037 \\
            5 & 16  & 0.0005& 0.5  & 0.23829 & 93.421 & 94.253 & 92.620 \\
            \bottomrule
        \end{tabular}
    }
  \caption{Die fünf Runs mit dem niedrigsten validation loss sowie deren verwendete Hyperparameter und aufgezeichnete Metriken.}
  \label{tab:hyperp-gli men}
\end{table}
Der erste Run besitzt zwar den niedrigsten validation loss, jedoch auch die niedrigste Accuracy und Specificity.
Der höchste Wert der Accuracy und Specificity tritt bei Run 3 auf
Aufgrund dessen werden in den folgenden Trainingsdurchläufen die Hyperparameter von Run 3 verwendet.
\subsection{Reduzierung der Trainingsdaten}
In Abbildung \ref{fig:gli-men-reduktion} ist der Verlauf der Accuracy, Sensitivity und Specificity bei der Reduktion der Training samples dargestellt.
Die dazu gehörigen Werte werden in der Tabelle \ref{tab:Red-gli-men} dargestellt.
Die drei Metriken steigen, mit zunehmender Anzahl an samples. 
Bei 851 Training samples sinken die Werte etwas, bevor sie anschließend wieder ansteigen.
Die Accuracy erhöht sich von \SI{76.4191}{\percent}, bei 231 Training samples auf \SI{92.3102}{\percent} bei 2128 Training samples.
Die Sensitivity steigt bis 1702 Training samples auf \SI{0.9186}{} an und bleibt anschließend weitgehend konstant zwischen \SI{0.9114}{} und \SI{0.9255}{}.
Die Specificity nimmt bis 1064 Training samples zu und bleibt bis 1277 konstant. 
Danach sinkt diese kurzzeitig etwas und steigt anschließend wieder an. 
Ab 1915 Training samples bleibt die Specificity stabil bei ungefähr \SI{0.92}{}.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/3-Messungen-Gli-Men_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:gli-men-acc}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/3-Messungen-Gli-Men_Sensitivity_mean.pdf}
    \caption{Sensitivität}
    \label{fig:gli-men-sens}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/3-Messungen-Gli-Men_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:gli-men-spec}
  \end{subfigure}
  \caption{Verlauf der Metriken bei der Reduzierung der Training samples für die Klassifikation zwischen Glioma und Meningioma.}
  \label{fig:gli-men-reduktion}
\end{figure}
\begin{table}[H]
    \centering
    {\small
        \begin{tabular}{cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            231  & $76.42 \pm 0.51 $ & $78.46 \pm 3.83$ & $74.33 \pm 3.49$\\
            426  & $78.66 \pm 0.70 $ & $80.20 \pm 4.14$ & $77.10 \pm 2.98$\\
            683  & $83.53 \pm 1.27 $ & $83.17 \pm 3.83$ & $83.90 \pm 2.49$\\
            851  & $81.83 \pm 1.29 $ & $82.09 \pm 2.38$ & $81.57 \pm 2.33$\\
            1064 & $87.11 \pm 1.25 $ & $86.67 \pm 3.78$ & $87.57 \pm 2.60$\\
            1277 & $87.72 \pm 0.65 $ & $88.17 \pm 2.70$ & $87.27 \pm 2.50$\\
            1490 & $88.12 \pm 0.89 $ & $90.16 \pm 1.58$ & $86.03 \pm 2.78$\\
            1702 & $90.66 \pm 0.59 $ & $91.86 \pm 1.17$ & $89.43 \pm 1.40$\\
            1915 & $91.67 \pm 0.92 $ & $91.14 \pm 2.14$ & $92.20 \pm 0.76$\\
            2128 & $92.31 \pm 0.83 $ & $92.55 \pm 1.65$ & $92.07 \pm 1.43$\\            
            \bottomrule
        \end{tabular}}
  \caption{Mittelwert und Standardabweichung für die Reduzierung der Training samples.}
  \label{tab:Red-gli-men}
\end{table}
\vspace{-3.5em}
\subsection{Augmentation}
%\vspace{-0.5em}
Unter Verwendung von Augmentation wurden die Training samples reduziert.
Der Verlauf der Metriken ist in der Abbildung \ref{fig:gli-men-augm} dargestellt,
die entsprechenden Werte sind in der Tabelle \ref{tab:gli-men-augm} zu finden.
Die Accuracy steigt kontinuierlich mit der verwendeten Sample Anzahl.
Zu beginn liegt sie bei \SI{75.8746}{\percent} für 212 samples. 
Bei der Nutzung aller verfügbaren Trainingsdaten erreicht \SI{92.1947}{\percent}.
Die Sensitivity steigt zunächst bis zu 425 Bildern an, sinkt anschließend etwas bei 638 Samples, nimmt danach jedoch wieder zu.
Ab 1702 samples bleibt sie konstant bei \SI{0.9101}{}, bevor sie bei 2128 Training samples auf \SI{0.9261} ansteigt. 
Der Anstieg der Specificity erfolgt konstant bis 1064 Training sample und flacht anschließend ab.
Bei 2128 Samples wird eine Specificity von \SI{0.9177}{} erreicht.
\begin{table}[H]
    \centering
    {\small
        \begin{tabular}{cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            212  & $75.87 \pm 0.61$ & $78.01 \pm 5.64$ & $ 73.70 \pm 6.56$ \\
            425  & $79.72 \pm 0.44$ & $81.99 \pm 1.47$ & $ 77.40 \pm 1.62$ \\
            638  & $80.69 \pm 0.57$ & $79.58 \pm 1.70$ & $ 81.83 \pm 0.85$ \\
            851  & $81.55 \pm 0.98$ & $81.70 \pm 2.28$ & $ 81.40 \pm 1.34$ \\
            1064 & $86.45 \pm 0.82$ & $85.26 \pm 2.39$ & $ 87.67 \pm 1.91$ \\
            1276 & $87.99 \pm 0.85$ & $87.68 \pm 1.80$ & $ 88.30 \pm 2.02$ \\
            1489 & $89.01 \pm 1.19$ & $88.86 \pm 2.21$ & $ 89.17 \pm 1.96$ \\
            1702 & $90.71 \pm 0.56$ & $91.01 \pm 2.09$ & $ 90.40 \pm 1.75$ \\
            1915 & $91.27 \pm 1.20$ & $91.01 \pm 1.82$ & $ 91.53 \pm 1.21$ \\
            2128 & $92.19 \pm 0.88$ & $92.61 \pm 1.39$ & $ 91.77 \pm 1.23$ \\         
            \bottomrule
        \end{tabular}}
  \caption{Mittelwert und Standardabweichung der drei Metriken bei Reduzierung der Training samples unter Verwendung von Augmentation für die Klassifikation zwischen Glioma und Meningioma.}
  \label{tab:gli-men-augm}
\end{table}
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Augm-Gli-Men_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:augm-acc}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Augm-Gli-Men_Sensitivity_mean.pdf}
    \caption{Sensitivität}
    \label{fig:augm-sens}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Augm-Gli-Men_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:augm-spec}
  \end{subfigure}
  \caption{Verlauf der Metriken bei Reduzierung der Training samples unter Verwendung von Augmentation für die Klassifikation zwischen Glioma und Meningioma.}
  \label{fig:gli-men-augm}
\end{figure}
\subsection{Reduzierung der Glioma sample}
Das Netzwerk wurde mit einer variierenden Anzahl an Glioma und konstanten Anzahl an Meningioma samples trainiert.
Der Verlauf der Metriken ist in der Abbildung \ref{fig:gli-men-gliored} dargestellt.
In der Tabelle \ref{tab:red-gli} sind die dargestellten Mittelwerte und Standardabweichungen aufgeführt. 
Es ist zu erkennen, dass die Accuracy und die Specificity zunächst bis zu 317 Glioma sample ansteigen und anschließend etwas absteigen.
Danach nehmen beide Werte erneut zu.
Die Accuracy wird ab 739 Glioma samples nahezu konstant bei etwa \SI{91}{\percent} und steigt bei 1057 Sample auf \SI{93.7459}{\percent} an.
Die Specificity schwankt im Bereich zwischen 739 und 951 Glioma samples zwischen \SI{0.8967}{} \SI{0.9177}{}.
Bei Verwendung aller verfügbaren Glioma samples erreicht sie einen Wert von \SI{0.9307}{}.
Die Sensitivity beträgt bei nur 105 verwendeten Glioma samples einen Wert von \SI{0.8056}{}.
Anschließende steigt sie deutlich an und schwankt im Bereich zwischen 211 und 951 Glioma samples zwischen \SI{0.8912}{} und \SI{0.9193}{}. 
Zum Schluss steigt sie bei 1057 Beispielen weiter auf \SI{0.9441}{}.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Reduzierung-Gli + Balnce_Accuracy_mean.pdf}
    \caption{Accuracy}
    \label{fig:gli-red-acc}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Reduzierung-Gli + Balnce_Sensitivity_mean.pdf}
    \caption{Sensitivität}
    \label{fig:gli-red-sens}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plots/Reduzierung-Gli + Balnce_Specificity_mean.pdf}
    \caption{Specificity}
    \label{fig:gli-red-spec}
  \end{subfigure}
  \caption{Verlauf der drei Metriken für die Reduzierung der Glioma Klasse.}
  \label{fig:gli-men-gliored}
\end{figure}
\begin{table}[H]
    \centering
    {\small
        \begin{tabular}{cccc}
            \toprule
            Training sample & Accuracy/$\%$ & Sensitivity/$\%$ & Specificity/$\%$\\
            \midrule
            105  & $78.94 \pm 1.51$ & $80.56 \pm 4.81$ & $ 77.30 \pm 3.20$ \\
            211  & $84.80 \pm 1.28$ & $89.12 \pm 3.88$ & $ 80.40 \pm 4.52$ \\
            317  & $86.62 \pm 1.75$ & $90.52 \pm 2.78$ & $ 82.63 \pm 4.04$ \\
            422  & $85.68 \pm 1.39$ & $89.41 \pm 4.09$ & $ 81.87 \pm 3.72$ \\
            528  & $87.10 \pm 1.86$ & $90.23 \pm 2.66$ & $ 83.90 \pm 3.52$ \\
            634  & $89.34 \pm 2.32$ & $91.34 \pm 2.35$ & $ 87.30 \pm 3.67$ \\
            739  & $90.46 \pm 1.20$ & $91.24 \pm 2.53$ & $ 89.67 \pm 3.01$ \\
            845  & $91.09 \pm 1.49$ & $90.42 \pm 2.30$ & $ 91.77 \pm 2.28$ \\
            951  & $91.04 \pm 1.83$ & $91.93 \pm 1.57$ & $ 90.13 \pm 3.95$ \\
            1057 & $93.75 \pm 1.69$ & $94.41 \pm 1.70$ & $ 93.07 \pm 2.35$ \\
            \bottomrule
        \end{tabular}}
  \caption{Mittelwert und Standardabweichung der Metriken für die Reduzierung der Glioma samples.}
  \label{tab:red-gli}
\end{table}

